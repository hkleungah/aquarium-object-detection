{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\tf_gpu_2_6_0_env\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\Users\\User\\anaconda3\\envs\\tf_gpu_2_6_0_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll\n",
      "d:\\Users\\User\\anaconda3\\envs\\tf_gpu_2_6_0_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'fish'}, 2: {'id': 2, 'name': 'jellyfish'}, 3: {'id': 3, 'name': 'penguin'}, 4: {'id': 4, 'name': 'puffin'}, 5: {'id': 5, 'name': 'shark'}, 6: {'id': 6, 'name': 'starfish'}, 7: {'id': 7, 'name': 'stingray'}}\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "ANNOTATION_PATH = 'data/test/creatures_label_map.pbtxt' \n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH, use_display_name=True)\n",
    "\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 11.488907814025879 seconds\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVED_MODEL = \"./workspace/models/aquarium_model/exported_models/saved_model\"\n",
    "\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detector = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import numpy as np\n",
    "\n",
    "def apply_detector_to_video(video_input_path, video_output_path, detector, category_index, min_score_thresh=0.3):\n",
    "    # Open the video file\n",
    "    video_reader = cv2.VideoCapture(video_input_path)\n",
    "\n",
    "    # Get the width, height, and frames per second (fps) of the video\n",
    "    width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # fps = video_reader.get(cv2.CAP_PROP_FPS)\n",
    "    fps = 32.75\n",
    "\n",
    "    # Create a VideoWriter object to write the output video\n",
    "    video_writer = cv2.VideoWriter(video_output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "\n",
    "    while video_reader.isOpened():\n",
    "        ret, frame = video_reader.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image to a tensor\n",
    "        input_tensor = tf.convert_to_tensor(frame)\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "        # Apply the model to the frame\n",
    "        detections = detector(input_tensor)\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        # Visualize the predicted bboxes on the frame\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                frame,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'],\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=200,\n",
    "                min_score_thresh=min_score_thresh,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    # Close the video file\n",
    "    video_reader.release()\n",
    "    video_writer.release()\n",
    "\n",
    "# Now you can call apply_detector_to_video with the paths to your input and output videos.\n",
    "apply_detector_to_video('input1.mp4', 'output1.mp4', detector, category_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_2_6_0_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
